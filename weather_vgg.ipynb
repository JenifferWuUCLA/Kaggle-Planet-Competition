{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# package\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from six import string_types\n",
    "\n",
    "# Make sure you have all of these packages installed, e.g. via pip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy\n",
    "from skimage import io\n",
    "from scipy import ndimage\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PLANET_KAGGLE_ROOT = os.path.abspath(\"./\")\n",
    "PLANET_KAGGLE_JPEG_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\n",
    "PLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_v2.csv')\n",
    "assert os.path.exists(PLANET_KAGGLE_ROOT)\n",
    "assert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\n",
    "assert os.path.exists(PLANET_KAGGLE_LABEL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\n",
    "labels_df.head()\n",
    "label_list = ['agriculture', 'artisinal_mine', 'bare_ground', 'blooming', 'blow_down', 'clear',\n",
    "              'cloudy', 'conventional_mine', 'cultivation', 'habitation', 'haze', 'partly_cloudy',\n",
    "              'primary', 'road', 'selective_logging', 'slash_burn', 'water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>blooming</th>\n",
       "      <th>blow_down</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>habitation</th>\n",
       "      <th>haze</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>primary</th>\n",
       "      <th>road</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>water</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags  agriculture  \\\n",
       "0    train_0                               haze primary            0   \n",
       "1    train_1            agriculture clear primary water            1   \n",
       "2    train_2                              clear primary            0   \n",
       "3    train_3                              clear primary            0   \n",
       "4    train_4  agriculture clear habitation primary road            1   \n",
       "\n",
       "   artisinal_mine  bare_ground  blooming  blow_down  clear  cloudy  \\\n",
       "0               0            0         0          0      0       0   \n",
       "1               0            0         0          0      1       0   \n",
       "2               0            0         0          0      1       0   \n",
       "3               0            0         0          0      1       0   \n",
       "4               0            0         0          0      1       0   \n",
       "\n",
       "   conventional_mine  cultivation  habitation  haze  partly_cloudy  primary  \\\n",
       "0                  0            0           0     1              0        1   \n",
       "1                  0            0           0     0              0        1   \n",
       "2                  0            0           0     0              0        1   \n",
       "3                  0            0           0     0              0        1   \n",
       "4                  0            0           1     0              0        1   \n",
       "\n",
       "   road  selective_logging  slash_burn  water  \n",
       "0     0                  0           0      0  \n",
       "1     0                  0           0      1  \n",
       "2     0                  0           0      0  \n",
       "3     0                  0           0      0  \n",
       "4     1                  0           0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add onehot features for every label\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "# Display head\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "land_labels = ['primary', 'agriculture', 'water', 'habitation', 'road', 'cultivation', 'slash_burn', 'conventional_mine', 'bare_ground', 'artisinal_mine', 'blooming', 'selective_logging', 'blow_down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_labels_value = np.transpose(np.float32(labels_df[weather_labels].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation set\n",
    "# set 10% samples to validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "img_set = labels_df['image_name'].values\n",
    "labels_set = labels_df[label_list].values\n",
    "img_train, img_test, labels_train, labels_test = train_test_split(img_set, labels_set, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36431\n",
      "4048\n"
     ]
    }
   ],
   "source": [
    "print len(img_train)\n",
    "print len(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write train set\n",
    "import csv\n",
    "with open( './train_validation_v2_bin.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image_name'] + label_list)\n",
    "    for i in xrange(len(img_train)):\n",
    "        data = [img_train[i]] + labels_train[i].tolist()\n",
    "        writer.writerow(data)\n",
    "# write validation set\n",
    "with open( './validation_train_v2_bin.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['image_name'] + label_list)\n",
    "    for i in xrange(len(img_test)):\n",
    "        data = [img_test[i]] + labels_test[i].tolist()\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set:\n",
      "clear tags num: 25551\n",
      "partly_cloudy tags num: 6524\n",
      "haze tags num: 2442\n",
      "cloudy tags num: 1913\n",
      "\n",
      "validation set:\n",
      "clear tags num: 2880\n",
      "partly_cloudy tags num: 737\n",
      "haze tags num: 255\n",
      "cloudy tags num: 176\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv('./train_validation_v2_bin.csv')\n",
    "print \"train set:\"\n",
    "for l in weather_labels:\n",
    "    print l, \"tags num:\", np.sum(train_set[l])\n",
    "\n",
    "valid_set = pd.read_csv('./validation_train_v2_bin.csv')\n",
    "print \"\\nvalidation set:\"\n",
    "for l in weather_labels:\n",
    "    print l, \"tags num:\", np.sum(valid_set[l])\n",
    "# 可以发现随机抽样抽取的之后的每类样本数目大约是按照原先样本的分布比例分布的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_1 (3, 3, 512, 512) (512,)\n",
      "fc6 (25088, 4096) (4096,)\n",
      "conv5_3 (3, 3, 512, 512) (512,)\n",
      "conv5_2 (3, 3, 512, 512) (512,)\n",
      "fc8 (4096, 1000) (1000,)\n",
      "fc9 (1000, 4) (4,)\n",
      "fc7 (4096, 4096) (4096,)\n",
      "conv4_1 (3, 3, 256, 512) (512,)\n",
      "conv4_2 (3, 3, 512, 512) (512,)\n",
      "conv4_3 (3, 3, 512, 512) (512,)\n",
      "conv3_3 (3, 3, 256, 256) (256,)\n",
      "conv3_2 (3, 3, 256, 256) (256,)\n",
      "conv3_1 (3, 3, 128, 256) (256,)\n",
      "conv1_1 (3, 3, 3, 64) (64,)\n",
      "conv1_2 (3, 3, 64, 64) (64,)\n",
      "conv2_2 (3, 3, 128, 128) (128,)\n",
      "conv2_1 (3, 3, 64, 128) (128,)\n",
      "138361548 variables\n",
      "start training\n",
      "0 cost: 0.115634\n",
      "validation_f2_score: 0.908349802372\n",
      "('file saved', './params/vgg16_weather.npy')\n",
      "50 cost: 0.0792168\n",
      "100 cost: 0.0519398\n",
      "150 cost: 0.029727\n",
      "200 cost: 0.0590279\n",
      "250 cost: 0.16637\n",
      "300 cost: 0.356356\n",
      "350 cost: 0.15582\n",
      "400 cost: 0.0381264\n",
      "450 cost: 0.0455907\n",
      "500 cost: 0.0641322\n",
      "validation_f2_score: 0.935770750988\n",
      "('file saved', './params/vgg16_weather.npy')\n",
      "550 cost: 0.0907503\n",
      "600 cost: 0.0607102\n",
      "650 cost: 0.345959\n",
      "700 cost: 0.0267451\n",
      "750 cost: 0.0543465\n",
      "800 cost: 0.0701913\n",
      "850 cost: 0.074508\n",
      "900 cost: 0.387751\n",
      "950 cost: 0.294221\n"
     ]
    }
   ],
   "source": [
    "#train weather label with validation set\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "\n",
    "import vgg16_trainable as vgg16\n",
    "import read_data\n",
    "import utils\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    # fbeta_score throws a confusing error if inputs are not numpy arrays\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # We need to use average='samples' here, any other average method will generate bogus results\n",
    "    return fbeta_score(y_true, y_pred, beta=2, average='samples')\n",
    "\n",
    "def get_one_hot_pred(prob):\n",
    "    y_pred = list()\n",
    "    for p in prob:\n",
    "        temp = np.zeros(len(p))\n",
    "        temp[np.argmax(p)] = 1\n",
    "        y_pred.append(temp)\n",
    "    return y_pred\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "class Config():\n",
    "    batch_size = 8\n",
    "    steps = \"-1\"\n",
    "    gpu = '/gpu:0'\n",
    "\n",
    "    # checkpoint path and filename\n",
    "    logdir = \"./log\"\n",
    "    params_dir = \"./params/\"\n",
    "    load_filename = params_dir + \"vgg16_weather.npy\"\n",
    "    save_filename = params_dir + \"vgg16_weather.npy\"\n",
    "\n",
    "    # path\n",
    "    imgs_path = \"./train-jpg/\"\n",
    "    labels_file = \"./train_validation_v2_bin.csv\"\n",
    "\n",
    "    # iterations config\n",
    "    max_iteration = 1000\n",
    "    summary_iters = 50\n",
    "    # refer to synset.txt for the order of labels\n",
    "    # 6: clear, 7: cloudy, 11: haze, 12:partly_cloudy\n",
    "    usecols = [6, 7, 11, 12]\n",
    "config = Config()\n",
    "reader = read_data.Reader(config)\n",
    "\n",
    "validation_config = Config()\n",
    "validation_config.labels_file = \"./validation_train_v2_bin.csv\"\n",
    "validation_reader = read_data.Reader(validation_config)\n",
    "\n",
    "images = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "true_out = tf.placeholder(tf.float32, [None, len(config.usecols)])\n",
    "train_mode = tf.placeholder(tf.bool)\n",
    "\n",
    "vgg = vgg16.Vgg16(config.load_filename, output_size=len(config.usecols))\n",
    "vgg.build(images, train_mode)\n",
    "print vgg.get_var_count() , \"variables\"\n",
    "with tf.name_scope('loss'):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(true_out * tf.log(vgg.prob), [1]))\n",
    "    tf.summary.scalar('loss', cost)\n",
    "    valid_f2_score = 0\n",
    "    tf.summary.scalar('validf2_score', valid_f2_score)\n",
    "with tf.name_scope('train'):\n",
    "    rate = 1e-3\n",
    "    train = tf.train.GradientDescentOptimizer(rate).minimize(cost)\n",
    "    tf.summary.scalar('learning_rate', rate)\n",
    "    tf.summary.scalar('batch_size', config.batch_size)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.device(config.gpu):    \n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter(config.logdir, sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print \"start training\"\n",
    "    # start training\n",
    "    for idx in xrange(config.max_iteration):\n",
    "        imgs, labels = reader.random_batch()\n",
    "        # feed data into the model\n",
    "        feed_dict = {\n",
    "            images : imgs,\n",
    "            true_out : labels,\n",
    "            train_mode : True\n",
    "        }\n",
    "        sess.run(train, feed_dict=feed_dict)\n",
    "        if  idx % 50 == 0:\n",
    "            result = sess.run(merged, feed_dict=feed_dict)\n",
    "            loss = sess.run(cost, feed_dict=feed_dict)\n",
    "                        \n",
    "            print idx, \"cost:\", loss\n",
    "            writer.add_summary(result, idx)\n",
    "            if idx % 500 == 0:\n",
    "                valid_pred = []\n",
    "                valid_true_out = []\n",
    "                for x in  xrange(np.int32(np.ceil(4048/config.batch_size))):\n",
    "                    valid_img, valid_label = validation_reader.batch()\n",
    "                    valid_feed_dict = {\n",
    "                        images : valid_img,\n",
    "                        true_out: valid_label,\n",
    "                        train_mode : False\n",
    "                    }\n",
    "                    valid_prob = sess.run(vgg.prob, feed_dict=valid_feed_dict)\n",
    "                    valid_pred = np.append(valid_pred, get_one_hot_pred(valid_prob))\n",
    "                    valid_true_out = np.append(valid_true_out, valid_label)\n",
    "                valid_pred = np.reshape(valid_pred,[-1, len(config.usecols)])\n",
    "                valid_true_out = np.reshape(valid_true_out, [-1, len(config.usecols)])\n",
    "                valid_f2_score = f2_score(valid_true_out, valid_pred)\n",
    "                print \"validation_f2_score:\", valid_f2_score\n",
    "                vgg.save_npy(sess, config.save_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_1 (3, 3, 512, 512) (512,)\n",
      "fc6 (25088, 4096) (4096,)\n",
      "conv5_3 (3, 3, 512, 512) (512,)\n",
      "conv5_2 (3, 3, 512, 512) (512,)\n",
      "fc8 (4096, 1000) (1000,)\n",
      "fc9 (1000, 4) (4,)\n",
      "fc7 (4096, 4096) (4096,)\n",
      "conv4_1 (3, 3, 256, 512) (512,)\n",
      "conv4_2 (3, 3, 512, 512) (512,)\n",
      "conv4_3 (3, 3, 512, 512) (512,)\n",
      "conv3_3 (3, 3, 256, 256) (256,)\n",
      "conv3_2 (3, 3, 256, 256) (256,)\n",
      "conv3_1 (3, 3, 128, 256) (256,)\n",
      "conv1_1 (3, 3, 3, 64) (64,)\n",
      "conv1_2 (3, 3, 64, 64) (64,)\n",
      "conv2_2 (3, 3, 128, 128) (128,)\n",
      "conv2_1 (3, 3, 64, 128) (128,)\n",
      "138361548 variables\n",
      "start training\n",
      "0 cost: 0.0174124\n",
      "validation_f2_score: 0.9375\n",
      "('file saved', './params/vgg16_weather.npy')\n",
      "50 cost: 0.0341956\n",
      "100 cost: 0.399679\n",
      "150 cost: 0.0184284\n",
      "200 cost: 0.0593757\n",
      "250 cost: 0.0116394\n",
      "300 cost: 0.00857606\n",
      "350 cost: 0.0663076\n",
      "400 cost: 0.158414\n",
      "450 cost: 0.0911786\n",
      "500 cost: 0.158284\n",
      "validation_f2_score: 0.936017786561\n",
      "('file saved', './params/vgg16_weather.npy')\n"
     ]
    }
   ],
   "source": [
    "#train without validation set\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "\n",
    "import vgg16_trainable as vgg16\n",
    "import read_data\n",
    "import utils\n",
    "import csv\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def f2_score(y_true, y_pred):\n",
    "    # fbeta_score throws a confusing error if inputs are not numpy arrays\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # We need to use average='samples' here, any other average method will generate bogus results\n",
    "    return fbeta_score(y_true, y_pred, beta=2, average='samples')\n",
    "\n",
    "def get_one_hot_pred(prob):\n",
    "    y_pred = list()\n",
    "    for p in prob:\n",
    "        temp = np.zeros(len(p))\n",
    "        temp[np.argmax(p)] = 1\n",
    "        y_pred.append(temp)\n",
    "    return y_pred\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "class Config():\n",
    "    batch_size = 8\n",
    "    steps = \"-1\"\n",
    "    gpu = '/gpu:0'\n",
    "\n",
    "    # checkpoint path and filename\n",
    "    logdir = \"./log\"\n",
    "    params_dir = \"./params/\"\n",
    "    load_filename = params_dir + \"vgg16_weather.npy\"\n",
    "    save_filename = params_dir + \"vgg16_weather.npy\"\n",
    "\n",
    "    # path\n",
    "    imgs_path = \"./train-jpg/\"\n",
    "    labels_file = \"./train_v2_bin.csv\"\n",
    "\n",
    "    # iterations config\n",
    "    max_iteration = 501\n",
    "    summary_iters = 50\n",
    "    # refer to synset.txt for the order of labels\n",
    "    # 6: clear, 7: cloudy, 11: haze, 12:partly_cloudy\n",
    "    usecols = [6, 7, 11, 12]\n",
    "config = Config()\n",
    "reader = read_data.Reader(config)\n",
    "\n",
    "validation_config = Config()\n",
    "validation_config.labels_file = \"./validation_train_v2_bin.csv\"\n",
    "validation_reader = read_data.Reader(validation_config)\n",
    "\n",
    "images = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "true_out = tf.placeholder(tf.float32, [None, len(config.usecols)])\n",
    "train_mode = tf.placeholder(tf.bool)\n",
    "\n",
    "vgg = vgg16.Vgg16(config.load_filename, output_size=len(config.usecols))\n",
    "vgg.build(images, train_mode)\n",
    "print vgg.get_var_count() , \"variables\"\n",
    "with tf.name_scope('loss'):\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(true_out * tf.log(vgg.prob), [1]))\n",
    "    tf.summary.scalar('loss', cost)\n",
    "    valid_f2_score = 0\n",
    "    tf.summary.scalar('validf2_score', valid_f2_score)\n",
    "with tf.name_scope('train'):\n",
    "    rate = 1e-3\n",
    "    train = tf.train.GradientDescentOptimizer(rate).minimize(cost)\n",
    "    tf.summary.scalar('learning_rate', rate)\n",
    "    tf.summary.scalar('batch_size', config.batch_size)\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "with tf.device(config.gpu):    \n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter(config.logdir, sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print \"start training\"\n",
    "    # start training\n",
    "    for idx in xrange(config.max_iteration):\n",
    "        imgs, labels = reader.random_batch()\n",
    "        # feed data into the model\n",
    "        feed_dict = {\n",
    "            images : imgs,\n",
    "            true_out : labels,\n",
    "            train_mode : True\n",
    "        }\n",
    "        sess.run(train, feed_dict=feed_dict)\n",
    "        if  idx % 50 == 0:\n",
    "            result = sess.run(merged, feed_dict=feed_dict)\n",
    "            loss = sess.run(cost, feed_dict=feed_dict)\n",
    "                        \n",
    "            print idx, \"cost:\", loss\n",
    "            writer.add_summary(result, idx)\n",
    "            if idx % 500 == 0:\n",
    "                valid_pred = []\n",
    "                valid_true_out = []\n",
    "                for x in  xrange(np.int32(np.ceil(4048/config.batch_size))):\n",
    "                    valid_img, valid_label = validation_reader.batch()\n",
    "                    valid_feed_dict = {\n",
    "                        images : valid_img,\n",
    "                        true_out: valid_label,\n",
    "                        train_mode : False\n",
    "                    }\n",
    "                    valid_prob = sess.run(vgg.prob, feed_dict=valid_feed_dict)\n",
    "                    valid_pred = np.append(valid_pred, get_one_hot_pred(valid_prob))\n",
    "                    valid_true_out = np.append(valid_true_out, valid_label)\n",
    "                valid_pred = np.reshape(valid_pred,[-1, len(config.usecols)])\n",
    "                valid_true_out = np.reshape(valid_true_out, [-1, len(config.usecols)])\n",
    "                valid_f2_score = f2_score(valid_true_out, valid_pred)\n",
    "                print \"validation_f2_score:\", valid_f2_score\n",
    "                vgg.save_npy(sess, config.save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
